{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyMDYfz3K+BeNrJ/xAbk2zWn",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/fit-k23/number-plate-recognition/blob/main/number-plate-recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!sudo apt install tesseract-ocr -y\n",
    "!pip install pytesseract\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pytesseract as pt\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import xml.etree.ElementTree as xet\n",
    "\n",
    "from glob import glob\n",
    "from skimage import io\n",
    "from shutil import copy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications import InceptionResNetV2\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from PIL import Image\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ty_slLHtMiin",
    "outputId": "f84c6667-1004-461f-cd30-db566aedc970"
   },
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "The following additional packages will be installed:\n",
      "  tesseract-ocr-eng tesseract-ocr-osd\n",
      "The following NEW packages will be installed:\n",
      "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
      "0 upgraded, 3 newly installed, 0 to remove and 15 not upgraded.\n",
      "Need to get 4,816 kB of archives.\n",
      "After this operation, 15.6 MB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
      "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
      "Fetched 4,816 kB in 11s (423 kB/s)\n",
      "debconf: unable to initialize frontend: Dialog\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
      "debconf: falling back to frontend: Readline\n",
      "debconf: unable to initialize frontend: Readline\n",
      "debconf: (This frontend requires a controlling tty.)\n",
      "debconf: falling back to frontend: Teletype\n",
      "dpkg-preconfigure: unable to re-open stdin: \n",
      "Selecting previously unselected package tesseract-ocr-eng.\n",
      "(Reading database ... 120899 files and directories currently installed.)\n",
      "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
      "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
      "Selecting previously unselected package tesseract-ocr-osd.\n",
      "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
      "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
      "Selecting previously unselected package tesseract-ocr.\n",
      "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
      "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
      "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
      "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
      "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!cd drive/MyDrive/NPR"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "files = glob('input/dataset/annotations/*.xml')\n",
    "labels_dict = dict(filepath=[],xmin=[],xmax=[],ymin=[],ymax=[])\n",
    "for filename in files:\n",
    "    info = xet.parse(filename)\n",
    "    root = info.getroot()\n",
    "    member_object = root.findall('object')\n",
    "    for member in member_object:\n",
    "        labels_info = member.find('bndbox')\n",
    "        xmin = int(labels_info.find('xmin').text)\n",
    "        xmax = int(labels_info.find('xmax').text)\n",
    "        ymin = int(labels_info.find('ymin').text)\n",
    "        ymax = int(labels_info.find('ymax').text)\n",
    "    \n",
    "        labels_dict['filepath'].append(filename)\n",
    "        labels_dict['xmin'].append(xmin)\n",
    "        labels_dict['xmax'].append(xmax)\n",
    "        labels_dict['ymin'].append(ymin)\n",
    "        labels_dict['ymax'].append(ymax)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.DataFrame(labels_dict)\n",
    "df.to_csv('labels.csv',index=False)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def getImagePath(filename):\n",
    "    imagePath = xet.parse(filename).getroot().find('path').text\n",
    "    imagePath = os.path.join('input/dataset/images',imagePath)\n",
    "    return imagePath"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image_path = list(df['filepath'].apply(getImagePath))\n",
    "image_path[:10]#random check"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_path = image_path[0] #path of our image N2.jpeg\n",
    "img = cv2.imread(file_path) #read the image\n",
    "# xmin-1804/ymin-1734/xmax-2493/ymax-1882\n",
    "img = io.imread(file_path) #Read the image\n",
    "fig = px.imshow(img)\n",
    "fig.update_layout(width=600, height=500, margin=dict(l=10, r=10, b=10, t=10),xaxis_title='Figure 8 - N2.jpeg with bounding box')\n",
    "fig.add_shape(type='rect',x0=36, x1=465, y0=64, y1=168, xref='x', yref='y',line_color='cyan')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Targeting all our values in array selecting all columns\n",
    "labels = df.iloc[:,1:].values\n",
    "data = []\n",
    "output = []\n",
    "for ind in range(len(image_path)):\n",
    "    image = image_path[ind]\n",
    "    img_arr = cv2.imread(image)\n",
    "    h,w,d = img_arr.shape\n",
    "    # Prepprocesing\n",
    "    load_image = load_img(image,target_size=(224,224))\n",
    "    load_image_arr = img_to_array(load_image)\n",
    "    norm_load_image_arr = load_image_arr/255.0 # Normalization\n",
    "    # Normalization to labels\n",
    "    xmin,xmax,ymin,ymax = labels[ind]\n",
    "    nxmin,nxmax = xmin/w,xmax/w\n",
    "    nymin,nymax = ymin/h,ymax/h\n",
    "    label_norm = (nxmin,nxmax,nymin,nymax) # Normalized output\n",
    "    # Append\n",
    "    data.append(norm_load_image_arr)\n",
    "    output.append(label_norm)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert data to array\n",
    "X = np.array(data,dtype=np.float32)\n",
    "y = np.array(output,dtype=np.float32)\n",
    "\n",
    "# Split the data into training and testing set using sklearn.\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,y,train_size=0.8,random_state=0)\n",
    "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "inception_resnet = InceptionResNetV2(weights=\"imagenet\",include_top=False, input_tensor=Input(shape=(224,224,3)))\n",
    "# ---------------------\n",
    "headmodel = inception_resnet.output\n",
    "headmodel = Flatten()(headmodel)\n",
    "headmodel = Dense(500,activation=\"relu\")(headmodel)\n",
    "headmodel = Dense(250,activation=\"relu\")(headmodel)\n",
    "headmodel = Dense(4,activation='sigmoid')(headmodel)\n",
    "\n",
    "\n",
    "# ---------- model\n",
    "model = Model(inputs=inception_resnet.input,outputs=headmodel)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Complie model\n",
    "model.compile(loss='mse',optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4))\n",
    "model.summary()\n",
    "tfb = TensorBoard('object_detection')\n",
    "history = model.fit(x=x_train,y=y_train,batch_size=10,epochs=180,\n",
    "                    validation_data=(x_test,y_test),callbacks=[tfb])\n",
    "model.save('./my_model.keras')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = tf.keras.models.load_model('my_model.keras')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "path = 'test/test1.jpg'\n",
    "def object_detection(path):\n",
    "\n",
    "    # Read image\n",
    "    image = load_img(path) # PIL object\n",
    "    image = np.array(image,dtype=np.uint8) # 8 bit array (0,255)\n",
    "    image1 = load_img(path,target_size=(224,224))\n",
    "\n",
    "    # Data preprocessing\n",
    "    image_arr_224 = img_to_array(image1)/255.0 # Convert to array & normalized\n",
    "    h,w,d = image.shape\n",
    "    test_arr = image_arr_224.reshape(1,224,224,3)\n",
    "\n",
    "    # Make predictions\n",
    "    coords = model.predict(test_arr)\n",
    "\n",
    "    # Denormalize the values\n",
    "    denorm = np.array([w,w,h,h])\n",
    "    coords = coords * denorm\n",
    "    coords = coords.astype(np.int32)\n",
    "\n",
    "    # Draw bounding on top the image\n",
    "    xmin,xmax,ymin,ymax = coords[0]\n",
    "\n",
    "    xmin = xmin - 15\n",
    "    ymin = ymin + 15\n",
    "    xmax = xmax + 55\n",
    "    ymax = ymax + 25\n",
    "\n",
    "    pt1 =(xmin,ymin)\n",
    "    pt2 =(xmax,ymax)\n",
    "    print(pt1, pt2)\n",
    "    cv2.rectangle(image,pt1,pt2,(0,255,0),3)\n",
    "    return image, coords\n",
    "\n",
    "image, cods = object_detection(path)\n",
    "\n",
    "fig = px.imshow(image)\n",
    "fig.update_layout(width=700, height=500, margin=dict(l=10, r=10, b=10, t=10),xaxis_title='Figure 14')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def rotate_image(image, angle):\n",
    "  image_center = tuple(np.array(image.shape[1::-1]) / 2)\n",
    "  rot_mat = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n",
    "  result = cv2.warpAffine(image, rot_mat, image.shape[1::-1], flags=cv2.INTER_LINEAR)\n",
    "  return result\n",
    "\n",
    "img = np.array(load_img(path))\n",
    "xmin,xmax,ymin,ymax = cods[0]\n",
    "xmin = xmin - 15\n",
    "ymin = ymin + 15\n",
    "xmax = xmax + 55\n",
    "ymax = ymax + 25\n",
    "roi = img[ymin:ymax,xmin:xmax]\n",
    "\n",
    "roi = cv2.resize(roi,(0,0),fx=3,fy=2)\n",
    "# roi = cv2.GaussianBlur(roi,(11,11),0)\n",
    "# roi = cv2.medianBlur(roi,9)\n",
    "# roi = rotate_image(roi, 3)\n",
    "pt.charWhitelist = \" -.ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\\n\";\n",
    "text = pt.image_to_string(roi).rstrip()\n",
    "b = 10\n",
    "while b > 0 and text == \"\":\n",
    "    roi_temp = rotate_image(roi, 5 - b)\n",
    "    text = pt.image_to_string(roi_temp).rstrip()\n",
    "    print(str(5 - b) + \": \\\"\" + text + \"\\\"\\n\")\n",
    "    b = b - 1\n",
    "print(\"Out: \\\"\" + text + \"\\\"\")\n",
    "fig = px.imshow(roi)\n",
    "fig.update_layout(width=350, height=250, margin=dict(l=10, r=10, b=10, t=10),xaxis_title='Figure 15 Cropped image')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# extract text from image\n",
    "# text = pt.image_to_string(roi, config=\"-c tessedit_char_whitelist=' -.ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\\n' --psm 7\").rstrip()\n",
    "text = pt.image_to_string(roi, config=\"-c tessedit_char_whitelist=' -.ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\\n'\").rstrip()\n",
    "print(\"Out: \\\"\" + text + \"\\\"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
